\chapter{Kernels}
\label{h:kernels} 

\todo{enkel 3D}
\todo{nodige verhouding}

\todo{flop uitleggen}
\todo{in stapjes bla bla}

\section{Haalbaarheid F}
\label{h:kernels:f:haal}

\begin{align*}
	f &= \sum_{i = 1}^I \sum_{j = 1}^I \sum_{k = 1}^I \left( \left( \sum_{r=1}^{R} u^{(1)}_{i r} u^{(2)}_{j r} u^{(3)}_{k r} \right) - t_{ijk}\right)^2 \\
\end{align*}

Berekening aantal nodige flop voor een optimale implementatie.

\begin{tabular}{|r l|c| c|c|}
\hline
					&							& flop(sp)			& flop(dp) 			& \# geh. aanvragen	\\
\hline
$a_{ij r} $	&$= u^{(1)}_{i r} \cdot%
u^{(2)}_{j r}$									& $2 R \cdot I^2$	& $2 R \cdot I^2$	&	$2RI$			\\
$a_{ijk r} $&$= a_{ij r} \cdot u^{(3)}_{k r}$	& $2 R \cdot I^3$	& $2 R \cdot I^3$	&	$RI$			\\
$a_{ijk} $	&$= \sum_{r=1}^{R} a_{ijk r}$		& 0 (MAD)			& 0 (MAD)			&	$0$				\\
\hline
$a_{ijk} $	&$= a_{ijk}  - t_{ijk}$				& 0 (MAD)			& 0 (MAD)			&	$I^3$			\\
$a_{ijk} $	&$= a_{ijk} a_{ijk}$				& $2 I^3$			& $2 I^3$			&	0				\\
$f $		&$= \sum a_{ijk}$					& 0 (MAD)			& 0 (MAD)			&	0				\\
\hline
\end{tabular}

We kunnen het algoritme in twee stukken verdelen. De stukken die in O($R \cdot I^3$) keer uitgevoerd worden, en de stukken die $ I^3$ keer worden uitgevoerd. De twee stukken worden in bovenstaande tabel gescheiden door een horizontale lijn.

Voor het eerste stuk is het aantal flop per geheugenoperatie gelijk aan:
\[
    \frac{2R (I^2 + I^3)}{3RI} = \frac{2}{3}(I + I^2)
\]

Voor het tweede stuk is het aantal flop per geheugenoperatie gelijk aan:
\[
    \frac{2I^3}{I^3} = 2
\]

Als $I$ groot genoeg is kan het eerste stuk compenseren voor het tweede stuk. Voor de twee stukken samen is de verhouding gelijk aan:
\begin{align*}
    & \frac{2R (I^2 + I^3) + 2I^3}{3RI + I^3}\\
\end{align*}

Wanneer we dat evalueren voor $I = R = 50$, dan is de verhouding gelijk aan 98,11. Dit is ruim voldoende. We besluiten dat voor bepaalde realistische probleemgroottes het geheugen de rekenkracht niet zal beperken. Het is dus zeker de moeite om het algoritme te parallelliseren.

%\section{Indelen NDRange}
\section{Een eerste kernel}
De uiteindelijke kernel is een combinatie van vele optimalisaties. Om de lezer niet te overweldigen zullen we de kernel stap voor stap opbouwen. Bij elke stap zullen we ook meten hoeveel winst we met elke stap maken.\todo{punten kiezen en keuze motiveren}

Zie \todo{ref} voor de eerste versie van de kernel. We gaan nu elk onderdeel van de kernel toelichten.

\subsection{Voor de R-lus}


\subsection{Itereren over R}
Een eerste keuze die we moeten maken is of de index $r$ deel zal uit maken van de NDRange, of dat we binnen de kernel over R zullen itereren.

Stel dat we $r$ indelen op een dimensie van de NDRange. Dan moeten we twee kernels schrijven. Een eerste die $u^{(1)}_{i r} u^{(2)}_{j r} u^{(3)}_{k r}$ uitrekend en een tweede die rest van de berekeningen doet. Door deze opsplitsing ontstaan er $RI^3$ extra schrijfoperaties door de eerste kernel, en nog eens $RI^3$ extra leesoperaties door de tweede kernel. Hierdoor is er ongeveer maar \'e\'en rekenoperatie per geheugenoperatie en dit is onaanvaardbaar. Daarnaast zal er ook veel extra geheugen nodig zijn.

We besluiten dat we over R moeten itereren in de kernel.

%\subsection{$\tens{T}$ indelen in de NDRange}
\subsection{3DRange}
Nu we weten dat R geen deel zal uitmaken van de NDRange, moeten we T nog indelen. We bespreken twee alternatieven. Het eerste alternatief is dat we \'e\'en dimensie van de NDRange gebruiken en elk work-item laten overeenkomen met een element uit $\tens{T}$. De NDRange wordt dus een 1DRange. Omdat $\tens{T}$ in het geheugen gelineariseerd wordt, zal index van $\tens{T}$ in het geheugen overeenkomen met index van de work-item.
Het tweede alternatief is dat we alle drie de dimensies van de NDRange gebruiken. Hierbij zullen de drie indices van de work-item overeenkomen met de rijen van de drie factormatrices. De NDRange wordt voor dit alternatief een 3DRange.


\todo{Eeste kernels tonen enzo}
\todo{waarom 64 items/workitems}
\todo{work-items verspillen}
\todo{R-lus definieren}
\todo{nuttige rekenoperatie def.}

Uit de resultaten blijkt dat de 3DRange-versie over het algemeen effici\"enter is dan de 1DRange-versie. Laten we eens de leesoperatie binnen de R-lus van een volledige work-group bekijken. We mogen dit doen omdat de aanvragen gecacht worden in de L1-cache. Het aantal leesoperaties buiten de R-lus is even groot voor beide gevallen.

Stel dat voor alle work-items de tweede-mode-index en derde-mode-index gelijk is en enkel de eerste-mode-index verandert. Dan is het aantal leesoperaties binnen de R-lus gelijk aan $64 + 1 + 1 = 66$ over de hele work-group. Wanneer ook de tweede-mode index verandert gaat dit getal nog verder omhoog. 66 is dus het meest optimistisch aantal geheugenaanvragen.

We kunnen ook hetzelfde doen voor de 3DRange-versie. Het aantal geheugenaanvragen voor een hele work-group binnen de R-lus is gelijk aan $3 \cdot 4 = 12$. Dit is slechts een vijfde van het aantal aanvragen bij de 1D-versie voor dezelfde hoeveelheid rekenwerk. De 1DRange-versie heeft wel het voordeel dat het minder cachegeheugen vereist en minder extra work-items verspilt, maar dit weegt over het algemeen niet op tegen het verschil in aantal geheugenaanvragen.

\todo{def. twee delen van het algoritme}

Laten we even dieper ingaan op de verhouding tussen het aantal nuttige rekenoperaties en het aantal geheugenaanvragen voor een work-group voor de 3DRange-versie.
\begin{tabular}{|r l|c| c|c|}
\hline
					&							& flop(sp)			& flop(dp) 			& \# geh. aanvragen	\\
codefrag			&							& $2 \cdot 64 R$	& $2 \cdot 64 R$	&	$2\cdot4R$		\\
					&							& $2 \cdot 64 R$	& $2 \cdot 64 R$	& 	$4R$			\\
					&							& 0 (MAD)			& 0 (MAD)			& 	0				\\
\hline
					&							& 2					& 1					&					\\
\end{tabular}
De verhouding binnen de R-lus is slechts gelijk aan 21,33 \todo eenheid en kan de verhouding van het aantal nuttige rekenoperatie per geheugenaanvragen buiten de R-lus van \todo{invullen} niet opkrikken tot boven de nodige \todo{invullen} voor enkele precisie, of \todo{inv} voor dubbele precisie.

De verhouding voor de volledige kernel is gelijk aan
\todo{invullen}

\section{Meer werk per work-item}
Voorheen kwam \'e\'en work-item overeen met een blokje van $1 \times 1 \times 1$ elementen van $\tens{T}$ en elke work-group met een blokje van $4 \times 4 \times 4$ elementen van $\tens{T}$. We willen het bezettingsgraad opdrijven \todo{def. bezettingsgraad} door een work-group niet met een blokje van $4 \times 4 \times 4$ te laten overeenkomen, maar met een blok van $8 \times 8 \times 8$ of zelfs $16 \times 16 \times 16$. Een work-item zal dan een blok van $2 \times 2 \times 2$ of $4 \times 4 \times 4$ verwerken. We spreken over een 8x8x8 -of over 16x16x16-kernel. De oude versie noemen we een 4x4x4-kernel.

\subsection{Registergeheugen}
In de R-lus moeten we de elementen van $\tens{C}$ ergens kunnen opslaan. Voor een 16x16x16-kernel die een tensor met dubbele precisie verwerkt hebben we $8$ B/double $\times 16^3$ double/work-group $= 32KiB$. Elke work-item heeft zijn eigen stukje van $\tens{C}$ dat niet gedeeld moet worden met een ander work-item. Daarnaast zijn de indices bij het compilen al gekend. Daarom kiezen we er voor om het stukje van \CC op te slaan in het registergeheugen. Het registergeheugen is 256 KiB groot dus het stukje van \CC past er acht maal in.  Men mag echter niet vergeten dat de andere variabelen ook in het registergeheugen opgeslagen moeten worden. \todo{dit beperkt mogelijk performance voor double kernels} Dit beperkt dus het aantal work-items tot maximaal zeven. \todo{tabel maken}

\todo{<Nazien>}
\section{$\tens{T}$ lezen na constructie $\tens{C}$}
In alle voorgaande kernels berekenden we eerst $\tens{C}$ en trokken we dan $\tens{T}$ er van af. Hiervoor moesten we eerst $\tens{C}$ initialiseren naar 0. Misschien kunnen we eerst $\tens{T}$ lezen, en dan in elke iteratie over $R$ het product van de factormatrices aftrekken van $\tens{T}$. Het teken zal dan omgekeerd zijn, maar dat wordt ongedaan gemaakt door het kwadraat te nemen. Het is dan niet nodig om $\tens{C}$ te initialiseren naar 0.

\todo{testresultaten}

Waarom dat zo een klein verschil zo een impact kan hebben kunnen we als volgt verklaren. We veronderstellen dat R groot genoeg is zodat de algoritme in zijn geheel gelimiteerd wordt door de rekenkracht. Het algoritme bestaat uit twee delen: het deel binnen de R-lus dat gelimiteerd is door de rekenkracht en het deel buiten de R-lus dat geheugengelimiteerd is.

Als we eerst T inlezen bestaat het stuk voor de R-lus bijna volledige uit leesoperatie. De grafische kaart zal dan work-groups blijven activeren om de compute-units bezig te houden tot we op de limiet komen. In deze eerste fase wordt misschien het geheugen volledig gebruikt, maar de compute-units hebben amper werk. Er zijn ook veel work-items gelijktijdig actief en ze zitten allemaal in dezelfde fase op een paar instructies na.

Dan komt de tweede fase. Dit is het stuk binnen de R-lus. In deze fase kan het geheugen de compute-units niet meer volgen. We kunnen ook geen extra work-items meer activeren omdat we in de eerste fase al aan de limiet zaten.
\todo{</Nazien>}